{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2bh9RHhBztt",
        "outputId": "a218dba6-f785-48a7-ec53-c1abee9e593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/OnionOrNot.csv\")\n"
      ],
      "metadata": {
        "id": "Xe1URfwkCap6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Cleans the input text by performing a few basic operations.\"\"\"\n",
        "\n",
        "    # Step 1: Convert all text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Step 2: Remove any characters that are not alphabets (remove numbers, punctuation, etc.)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Step 3: Split the text into a list of words\n",
        "    words = text.split()\n",
        "\n",
        "    # Step 4: Remove common stopwords (like \"and\", \"the\", \"is\", etc.)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Step 5: Join the words back into a cleaned string\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "j1MM0vNaCmyr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cleaning to the text column\n",
        "\n",
        "data['cleaned_text'] = data['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "85mxPbL5Cmuu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Tokenization and Padding\n",
        "# Tokenizer converts text to a sequence of integers (word indices)\n",
        "max_words = 10000  # Maximum number of words to consider in the vocabulary\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data['cleaned_text'])"
      ],
      "metadata": {
        "id": "Si0rwlGQDczI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences and pad them to ensure uniform input size\n",
        "sequences = tokenizer.texts_to_sequences(data['cleaned_text'])\n",
        "max_length = max(len(seq) for seq in sequences)  # Define max sequence length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
      ],
      "metadata": {
        "id": "2Dnq6DKIDvU_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prepare labels and split data\n",
        "labels = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "FM6lVB1oD3_N"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "Y6L-7bCNGoz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Build the LSTM Model\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128, input_length=max_length),  # Embedding layer\n",
        "    LSTM(64, return_sequences=False),  # LSTM layer with 64 units\n",
        "    tf.keras.layers.Dropout(0.3),  # Dropout for regularization # Changed to tf.keras.layers.Dropout\n",
        "    Dense(64, activation='relu'),  # Fully connected dense layer\n",
        "    tf.keras.layers.Dropout(0.3),  # Additional dropout # Changed to tf.keras.layers.Dropout\n",
        "    Dense(1, activation='sigmoid')  # Output layer (sigmoid for binary classification)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoDVyrJSD38d",
        "outputId": "cf57c6d1-f32b-4fc2-bba2-929dec72b93a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the LSTM Model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Z8U13x53Lipe"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Early Stopping Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "kAqzCJTGLuHu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LSTM Model\n",
        "lstm_epochs = 50  # Set to 50 epochs\n",
        "batch_size = 32\n",
        "lstm_history = lstm_model.fit(X_train, y_train, validation_split=0.2, epochs=lstm_epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eyL-87BLxZS",
        "outputId": "e2ebc60f-a8a7-423c-e6d6-54e212c07261"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.6671 - loss: 0.6242 - val_accuracy: 0.7724 - val_loss: 0.5379\n",
            "Epoch 2/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7694 - loss: 0.5290 - val_accuracy: 0.6203 - val_loss: 0.6698\n",
            "Epoch 3/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6309 - loss: 0.6612 - val_accuracy: 0.6203 - val_loss: 0.6658\n",
            "Epoch 4/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6307 - loss: 0.6603 - val_accuracy: 0.6203 - val_loss: 0.6666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the LSTM Model\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"LSTM Model Test Loss: {lstm_loss:.4f}\")\n",
        "print(f\"LSTM Model Test Accuracy: {lstm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txM7sUt0L1G7",
        "outputId": "07494daa-4e4a-49c5-a9f6-32ec6b998524"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Model Test Loss: 0.5255\n",
            "LSTM Model Test Accuracy: 0.7808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM**"
      ],
      "metadata": {
        "id": "7h8I-DipGhk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional  # Import Bidirectional\n",
        "\n",
        "\n",
        "# Step 5: Build the BiLSTM Model\n",
        "bilstm_model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128, input_length=max_length),  # Embedding layer\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),  # Bidirectional LSTM layer with 64 units\n",
        "    tf.keras.layers.Dropout(0.3),  # Dropout for regularization\n",
        "    Dense(64, activation='relu'),  # Fully connected dense layer\n",
        "    tf.keras.layers.Dropout(0.3),  # Additional dropout\n",
        "    Dense(1, activation='sigmoid')  # Output layer (sigmoid for binary classification)\n",
        "])"
      ],
      "metadata": {
        "id": "21i46jdSGfsY"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the BiLSTM Model\n",
        "bilstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "WJmWomezD34x"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Add Early Stopping Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "PBLKrmF2HPGR"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the BiLSTM Model\n",
        "bilstm_epochs = 50  # Set to 50 epochs\n",
        "bilstm_history = bilstm_model.fit(X_train, y_train, validation_split=0.2, epochs=bilstm_epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GptDI0pGEbeo",
        "outputId": "26bb13c7-0356-4953-8a6a-5f95bb1c6d4f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7112 - loss: 0.5407 - val_accuracy: 0.8409 - val_loss: 0.3561\n",
            "Epoch 2/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9224 - loss: 0.2052 - val_accuracy: 0.8427 - val_loss: 0.3901\n",
            "Epoch 3/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.1097 - val_accuracy: 0.8336 - val_loss: 0.5712\n",
            "Epoch 4/50\n",
            "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0543 - val_accuracy: 0.8240 - val_loss: 0.7204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the BiLSTM Model\n",
        "bilstm_loss, bilstm_accuracy = bilstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"BiLSTM Model Test Loss: {bilstm_loss:.4f}\")\n",
        "print(f\"BiLSTM Model Test Accuracy: {bilstm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSGoI6ldMSs6",
        "outputId": "2e605642-22d8-4bbf-90e8-c20bc0edbc71"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM Model Test Loss: 0.3429\n",
            "BiLSTM Model Test Accuracy: 0.8458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Compare Models\n",
        "print(\"\\nComparison of Models:\")\n",
        "print(f\"LSTM Model - Loss: {lstm_loss:.4f}, Accuracy: {lstm_accuracy:.4f}\")\n",
        "print(f\"BiLSTM Model - Loss: {bilstm_loss:.4f}, Accuracy: {bilstm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbtelO_XEbYr",
        "outputId": "a845c501-53f2-465c-aade-c1ddc229a84c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of Models:\n",
            "LSTM Model - Loss: 0.5255, Accuracy: 0.7808\n",
            "BiLSTM Model - Loss: 0.3429, Accuracy: 0.8458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Classification Reports\n",
        "print(\"\\nLSTM Model Classification Report:\")\n",
        "lstm_predictions = (lstm_model.predict(X_test) > 0.5).astype(int)\n",
        "print(classification_report(y_test, lstm_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_nVGZwCMSFf",
        "outputId": "56cd9a6b-8e8d-4ed7-bd6c-995b22f1a6c4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM Model Classification Report:\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.83      3018\n",
            "           1       0.74      0.63      0.68      1782\n",
            "\n",
            "    accuracy                           0.78      4800\n",
            "   macro avg       0.77      0.75      0.76      4800\n",
            "weighted avg       0.78      0.78      0.78      4800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBiLSTM Model Classification Report:\")\n",
        "bilstm_predictions = (bilstm_model.predict(X_test) > 0.5).astype(int)\n",
        "print(classification_report(y_test, bilstm_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFV22UISFMit",
        "outputId": "c4ec9e13-83c4-4d81-ea11-067d817ef97a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BiLSTM Model Classification Report:\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      3018\n",
            "           1       0.82      0.75      0.78      1782\n",
            "\n",
            "    accuracy                           0.85      4800\n",
            "   macro avg       0.84      0.83      0.83      4800\n",
            "weighted avg       0.84      0.85      0.84      4800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2M-JKoJaFoNE"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}